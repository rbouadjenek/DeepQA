{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#  Copyright (c) 2021. Mohamed Reda Bouadjenek, Deakin University              +\n",
    "#           Email:  reda.bouadjenek@deakin.edu.au                              +\n",
    "#                                                                              +\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");             +\n",
    "#   you may not use this file except in compliance with the License.           +\n",
    "#    You may obtain a copy of the License at:                                  +\n",
    "#                                                                              +\n",
    "#                 http://www.apache.org/licenses/LICENSE-2.0                   +\n",
    "#                                                                              +\n",
    "#    Unless required by applicable law or agreed to in writing, software       +\n",
    "#    distributed under the License is distributed on an \"AS IS\" BASIS,         +\n",
    "#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  +\n",
    "#    See the License for the specific language governing permissions and       +\n",
    "#    limitations under the License.                                            +\n",
    "#                                                                              +\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be run on Google Colab!\n",
    "# !mkdir preprocessing/\n",
    "# !wget --directory-prefix=preprocessing/  https://raw.githubusercontent.com/rbouadjenek/DeepQA/master/DeepQA/preprocessing/__init__.py   > /dev/null 2> /dev/null \n",
    "# !wget --directory-prefix=preprocessing/ https://raw.githubusercontent.com/rbouadjenek/DeepQA/master/DeepQA/preprocessing/preprocessing.py  > /dev/null 2> /dev/null \n",
    "# !pip install tokenizers transformers keras_metrics > /dev/null 2> /dev/null \n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "use_tpu = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import tarfile\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer, BertConfig, TFBertModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from preprocessing.preprocessing import create_squad_examples, create_inputs_targets, get_SQuAD1, get_SQuAD2, get_NewsQA\n",
    "from keras.layers import LSTM, Input\n",
    "from tensorflow.keras.layers import InputSpec\n",
    "from keras.activations import tanh, softmax\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Set the random seeds\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max length value\n",
    "max_len = 300\n",
    "# Create the tokenizer\n",
    "save_path = os.path.expanduser(\"~\") + \"/.bert_base_uncased/\"\n",
    "if not os.path.exists(save_path):\n",
    "    slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    os.makedirs(save_path)\n",
    "    slow_tokenizer.save_pretrained(save_path)\n",
    "tokenizer = BertWordPieceTokenizer(save_path + \"vocab.txt\", lowercase=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw data\n",
    "\n",
    "# raw_train_data, raw_val_data, raw_test_data = get_SQuAD1()\n",
    "raw_train_data, raw_val_data, raw_test_data = get_SQuAD2()\n",
    "# raw_train_data, raw_val_data, raw_test_data = get_NewsQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "train_squad_examples, train_skipped_questions = create_squad_examples(raw_train_data, max_len, tokenizer, False)\n",
    "x_train, y1_train, y2_train, y3_train, train_total_skipped_questions = create_inputs_targets(train_squad_examples)\n",
    "print('Size: ', len(y1_train[0]))\n",
    "print('skipped_questions: ', train_skipped_questions)\n",
    "print('skipped_questions: ', train_total_skipped_questions)\n",
    "\n",
    "eval_squad_examples, val_skipped_questions = create_squad_examples(raw_val_data, max_len, tokenizer)\n",
    "x_eval, y1_eval, y2_eval, y3_eval, val_total_skipped_questions = create_inputs_targets(eval_squad_examples)\n",
    "print('Size: ', len(y1_eval[0]))\n",
    "print('skipped_questions: ', val_skipped_questions)\n",
    "print('skipped_questions: ', val_total_skipped_questions)\n",
    "\n",
    "test_squad_examples, test_skipped_questions = create_squad_examples(raw_test_data, max_len, tokenizer)\n",
    "x_test, y1_test, y2_test, y3_test, test_total_skipped_questions = create_inputs_targets(test_squad_examples)\n",
    "print('Size: ', len(y1_test[0]))\n",
    "print('skipped_questions: ', test_skipped_questions)\n",
    "print('skipped_questions: ', test_total_skipped_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Create the keras model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#  Acknowledgement:                                                            +\n",
    "#          The code in this cell has been borrowed from keon                   +\n",
    "#                     https://github.com/keon                                  +\n",
    "#               https://github.com/keon/pointer-networks                       +\n",
    "#                                                                              +\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class PointerLSTM(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "        PointerLSTM\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, hidden_dimensions, output_length=2, name='pointer', **kwargs):\n",
    "        super(PointerLSTM, self).__init__(\n",
    "            hidden_dimensions, name=name, **kwargs)\n",
    "        self.hidden_dimensions = hidden_dimensions\n",
    "        self.output_length = output_length\n",
    "        # Decoder\n",
    "        self.lstm = keras.layers.LSTM(hidden_dimensions, return_sequences=False, return_state=True)\n",
    "        \n",
    "        \n",
    "        self.B = keras.layers.Dense(1, use_bias=False)\n",
    "        \n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(PointerLSTM, self).build(input_shape)\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "\n",
    "    def call(self, x, states=None):\n",
    "        \"\"\"\n",
    "        :param Tensor x: Should be the output of the decoder\n",
    "        :param Tensor states: last state of the decoder\n",
    "        :param Tensor mask: The mask to apply\n",
    "        :return: Pointers probabilities\n",
    "        \"\"\"\n",
    "\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        en_seq = x\n",
    "        x_input = x[:, input_shape[1] - 1, :]\n",
    "        x_input = K.repeat(x_input, input_shape[1])\n",
    "        if states:\n",
    "            initial_states = states\n",
    "        else:\n",
    "            initial_states = self.get_initial_state(x_input)\n",
    "\n",
    "        constants = []\n",
    "        preprocessed_input, _, constants = self.process_inputs(\n",
    "            x_input, initial_states, constants)\n",
    "        constants.append(en_seq)\n",
    "        \n",
    "#         print('initial_states[0].shape>',initial_states[0].shape)\n",
    "#         print('initial_states[1].shape>',initial_states[1].shape)\n",
    "\n",
    "        \n",
    "        last_output, outputs, states = K.rnn(self.step, preprocessed_input[:,0:self.output_length,:],\n",
    "                                             initial_states,\n",
    "                                             go_backwards=False,\n",
    "                                             constants=constants,\n",
    "                                             input_length=input_shape[1])\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "    def step(self, x_input, states):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "                \n",
    "        a= K.repeat(x_input, input_shape[1])\n",
    "        c = self.B(a)                \n",
    "        d = K.squeeze(c, axis=-1)       \n",
    "        \n",
    "        \n",
    "        x_input = K.expand_dims(x_input,1)\n",
    "        return d, [states[0], states[1]]\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        # output shape is not affected by the attention component\n",
    "        return (input_shape[0], input_shape[1], input_shape[1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], input_shape[1])\n",
    "    \n",
    "    def get_initial_state(self, inputs):\n",
    "        return self.lstm.get_initial_state(inputs)\n",
    "\n",
    "    def process_inputs(self, x_input, initial_states, constants):\n",
    "        return self.lstm._process_inputs(x_input, initial_states, constants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# main_input = Input(shape=(300, 768), name='main_input')\n",
    "\n",
    "# encoder,state_h, state_c = LSTM(768,return_sequences = True, name=\"encoder\",return_state=True)(main_input)\n",
    "# decoder = PointerLSTM()\n",
    "\n",
    "# output = decoder(encoder,states=[state_h, state_c])\n",
    "\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def create_model(learn_rate=5e-5, dropout_prob=0.3):\n",
    "    ## BERT encoder \n",
    "    configuration = BertConfig(hidden_dropout_prob=dropout_prob, attention_probs_dropout_prob=dropout_prob) \n",
    "    encoder = TFBertModel.from_pretrained(\"bert-base-uncased\", config=configuration)\n",
    "    ## QA Model\n",
    "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"token_type_ids\")\n",
    "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\") \n",
    "    \n",
    "    embedding = encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)[0]\n",
    "    \n",
    "#     state_h = embedding[:,0,:]\n",
    "#     state_c = embedding[:,0,:]\n",
    "#     print(state_h.shape)\n",
    "    \n",
    "    decoder = PointerLSTM(2)(embedding)\n",
    "    \n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=[input_ids, token_type_ids, attention_mask],\n",
    "        outputs=decoder,\n",
    "    )\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=learn_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'],\n",
    "                  run_eagerly=False) \n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_tpu:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "for lr in [9e-06, 1e-05, 3e-05, 5e-05, 7e-05, 9e-05, 1e-04]:\n",
    "    for dropout_prob in [0, 0.2, 0.4, 0.6]:\n",
    "        print(\"Learning rate = \" + str(lr) + \", dropout_prob = \" + str(dropout_prob))\n",
    "        np.random.seed(1)\n",
    "        random.seed(1)\n",
    "        tf.random.set_seed(1)\n",
    "        if use_tpu: \n",
    "            with strategy.scope():\n",
    "                model = create_model(lr, dropout_prob)\n",
    "        else:\n",
    "            model = create_model(lr, dropout_prob) \n",
    "        history = model.fit(\n",
    "            x_train,\n",
    "            ,\n",
    "            validation_data=(x_eval,),\n",
    "            epochs=20, \n",
    "            verbose=1,\n",
    "            batch_size=128,\n",
    "            callbacks=[callback],\n",
    "        )\n",
    "        results = model.evaluate(x_eval, y2_eval, batch_size=128)\n",
    "        print(f\"Results validation: {results}, Learning rate =  {lr}, dropout_prob = {dropout_prob}\")\n",
    "        print('-'*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "# SQuAD1.1\n",
    "# file_name = \"SQuAD1.1_\"\n",
    "# lr = 5e-05\n",
    "# dropout_prob = 0.2\n",
    "\n",
    "# SQuAD2.0\n",
    "# file_name = \"SQuAD2.0_\"\n",
    "# lr = 5e-05\n",
    "# dropout_prob = 0.2\n",
    "\n",
    "# NewsQA\n",
    "# file_name = \"NewsQA_\"\n",
    "# lr = 9E-06\n",
    "# dropout_prob = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "if use_tpu: \n",
    "    with strategy.scope():\n",
    "        model = create_model(lr, dropout_prob)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y1_train,\n",
    "    validation_data=(x_eval, y4_eval),\n",
    "    epochs=20, \n",
    "    verbose=1,\n",
    "    batch_size=128,\n",
    "    callbacks=[callback],\n",
    ")\n",
    "model.evaluate(x_test, y1_test, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(x_test, verbose=1)\n",
    "eval_pred = model.predict(x_eval, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip and copy the results\n",
    "\n",
    "algorithm = \"Answer_Pointer_BM_\"\n",
    "file_list = []\n",
    "\n",
    "def save_to_file(name, data):\n",
    "    json_string = json.dumps(data.tolist())\n",
    "    file = algorithm + file_name + name\n",
    "    file_list.append(file)\n",
    "    with open(file, \"w\") as text_file:\n",
    "        text_file.write(json_string)\n",
    "\n",
    "save_to_file(\"test_pred.txt\", test_pred)\n",
    "save_to_file(\"eval_pred.txt\", eval_pred)\n",
    "\n",
    "save_to_file(\"y2_eval.txt\", y2_eval)\n",
    "save_to_file(\"y3_eval.txt\", np.array([v.tolist() for v in y3_eval]))\n",
    "save_to_file(\"y4_eval.txt\", y4_eval)\n",
    "\n",
    "save_to_file(\"y2_test.txt\", y2_test)\n",
    "save_to_file(\"y3_test.txt\", np.array([v.tolist() for v in y3_test]))\n",
    "save_to_file(\"y4_test.txt\", y4_test)\n",
    "\n",
    "\n",
    "\n",
    "save_to_file(\"token_type_eval.txt\", x_eval[1])\n",
    "save_to_file(\"token_type_test.txt\", x_test[1])\n",
    "\n",
    "save_to_file(\"input_ids_test.txt\", x_test[0])\n",
    "\n",
    "\n",
    "tar = tarfile.open(algorithm + file_name + \"predictions.tar.gz\", \"w:gz\")\n",
    "for name in file_list:\n",
    "    tar.add(name)\n",
    "tar.close()\n",
    "\n",
    "!mv *predictions.tar.gz /content/drive/MyDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(5e-05, 0)\n",
    "i = 4\n",
    "history = model.fit(\n",
    "        [x_test[0][0:i],x_test[1][0:i],x_test[2][0:i]],\n",
    "        y2_test[0:i],\n",
    "        epochs=20, \n",
    "        verbose=1,\n",
    "        batch_size=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y2_test[0:i]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class fakeLayer(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    def build( self, input_shape):\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        keras_shape = keras.backend.int_shape(inputs) #tuple containing None and numbers\n",
    "        tf_shape_tuple = tuple(-1 if s is None else s for s in keras_shape) #None -> -1\n",
    "        print(tf_shape_tuple)\n",
    "        print(inputs.shape)\n",
    "        print(tf.reshape(inputs , tf_shape_tuple).shape)\n",
    "        return tf.reshape(inputs , tf_shape_tuple)\n",
    "\n",
    "\n",
    "inp = keras.layers.Input((32,32,3))\n",
    "x = keras.layers.Conv2D(16, (3,3))(inp)\n",
    "x = fakeLayer()(x)\n",
    "# x = keras.layers.Flatten()(x)\n",
    "# x = keras.layers.Dense(1)(x)\n",
    "model = keras.models.Model(inputs= inp, outputs = x)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
