{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#  Copyright (c) 2021. Mohamed Reda Bouadjenek, Deakin University              +\n",
    "#           Email:  reda.bouadjenek@deakin.edu.au                              +\n",
    "#                                                                              +\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");             +\n",
    "#   you may not use this file except in compliance with the License.           +\n",
    "#    You may obtain a copy of the License at:                                  +\n",
    "#                                                                              +\n",
    "#                 http://www.apache.org/licenses/LICENSE-2.0                   +\n",
    "#                                                                              +\n",
    "#    Unless required by applicable law or agreed to in writing, software       +\n",
    "#    distributed under the License is distributed on an \"AS IS\" BASIS,         +\n",
    "#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  +\n",
    "#    See the License for the specific language governing permissions and       +\n",
    "#    limitations under the License.                                            +\n",
    "#                                                                              +\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be run on Google Colab!\n",
    "# !mkdir preprocessing/\n",
    "# !wget --directory-prefix=preprocessing/  https://raw.githubusercontent.com/rbouadjenek/DeepQA/master/DeepQA/preprocessing/__init__.py   > /dev/null 2> /dev/null \n",
    "# !wget --directory-prefix=preprocessing/ https://raw.githubusercontent.com/rbouadjenek/DeepQA/master/DeepQA/preprocessing/preprocessing.py  > /dev/null 2> /dev/null \n",
    "# !pip install tokenizers transformers keras_metrics > /dev/null 2> /dev/null \n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "use_tpu = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import tarfile\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer, BertConfig, TFBertModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from preprocessing.preprocessing import create_squad_examples, create_inputs_targets, get_SQuAD1, get_SQuAD2, get_NewsQA\n",
    "\n",
    "# Set the random seeds\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max length value\n",
    "max_len = 300\n",
    "# Create the tokenizer\n",
    "save_path = os.path.expanduser(\"~\") + \"/.bert_base_uncased/\"\n",
    "if not os.path.exists(save_path):\n",
    "    slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    os.makedirs(save_path)\n",
    "    slow_tokenizer.save_pretrained(save_path)\n",
    "tokenizer = BertWordPieceTokenizer(save_path + \"vocab.txt\", lowercase=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw data\n",
    "\n",
    "# raw_train_data, raw_val_data, raw_test_data = get_SQuAD1()\n",
    "raw_train_data, raw_val_data, raw_test_data = get_SQuAD2()\n",
    "# raw_train_data, raw_val_data, raw_test_data = get_NewsQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "train_squad_examples, train_skipped_questions = create_squad_examples(raw_train_data, max_len, tokenizer, False)\n",
    "x_train, y1_train, y2_train, y3_train, train_total_skipped_questions = create_inputs_targets(train_squad_examples)\n",
    "print('Size: ', len(y1_train[0]))\n",
    "print('skipped_questions: ', train_skipped_questions)\n",
    "print('skipped_questions: ', train_total_skipped_questions)\n",
    "\n",
    "eval_squad_examples, val_skipped_questions = create_squad_examples(raw_val_data, max_len, tokenizer)\n",
    "x_eval, y1_eval, y2_eval, y3_eval, val_total_skipped_questions = create_inputs_targets(eval_squad_examples)\n",
    "print('Size: ', len(y1_eval[0]))\n",
    "print('skipped_questions: ', val_skipped_questions)\n",
    "print('skipped_questions: ', val_total_skipped_questions)\n",
    "\n",
    "test_squad_examples, test_skipped_questions = create_squad_examples(raw_test_data, max_len, tokenizer)\n",
    "x_test, y1_test, y2_test, y3_test, test_total_skipped_questions = create_inputs_targets(test_squad_examples)\n",
    "print('Size: ', len(y1_test[0]))\n",
    "print('skipped_questions: ', test_skipped_questions)\n",
    "print('skipped_questions: ', test_total_skipped_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Create the keras model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the f1-score measure to be used during training\n",
    "\n",
    "def recall_m(y_true, y_pred):     \n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1:] * y_pred[:,1:], 0, 1)), axis=1) + 1 \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true[:,1:], 0, 1)), axis=1) + 1\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives =  K.sum(K.round(K.clip(y_true[:,1:] * y_pred[:,1:], 0, 1)), axis=1) + 1\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred[:,1:], 0, 1)), axis=1) + 1\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)    \n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    f1_score = (2*precision*recall)/(precision+recall+K.epsilon())\n",
    "    return K.mean(f1_score)\n",
    "\n",
    "\n",
    "def exact_match(y_true, y_pred):\n",
    "    clf_positives = K.sum(K.round(y_pred[:,1:]), axis=1)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true[:,1:], 0, 1)), axis=1)\n",
    "    accuracy_boolean = clf_positives == possible_positives\n",
    "    accuracy = K.cast(accuracy_boolean, K.floatx())\n",
    "    return  accuracy\n",
    "\n",
    "def answerability_accuracy(y_true, y_pred):     \n",
    "    return K.cast(K.equal(K.round(K.clip(y_pred[:,0], 0, 1)),\n",
    "                          y_true[:,0]),\n",
    "                          K.floatx()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def create_model(learn_rate=5e-5, dropout_prob=0.3):\n",
    "    ## BERT encoder \n",
    "    configuration = BertConfig(hidden_dropout_prob=dropout_prob, attention_probs_dropout_prob=dropout_prob) \n",
    "    encoder = TFBertModel.from_pretrained(\"bert-base-uncased\", config=configuration)\n",
    "    ## QA Model\n",
    "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"token_type_ids\")\n",
    "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\") \n",
    "    \n",
    "    embedding = encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)[0]\n",
    "    \n",
    "    out = layers.Dense(1, name=\"logit\", use_bias=False)(embedding)\n",
    "    out = layers.Flatten()(out)\n",
    "    out = layers.Dropout(dropout_prob)(out)\n",
    "    out = layers.Activation(keras.activations.sigmoid)(out)\n",
    "    model = keras.Model(\n",
    "        inputs=[input_ids, token_type_ids, attention_mask],\n",
    "        outputs=[out],\n",
    "    )\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    optimizer = keras.optimizers.Adam(lr=learn_rate)\n",
    "    model.compile(optimizer=optimizer, loss=[loss], metrics=[exact_match, answerability_accuracy, f1_m, precision_m, recall_m], \n",
    "                  run_eagerly=False) \n",
    "    print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_tpu:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "for lr in [9e-06, 1e-05, 3e-05, 5e-05, 7e-05, 9e-05, 1e-04]:\n",
    "    for dropout_prob in [0, 0.2, 0.4, 0.6]:\n",
    "        print(\"Learning rate = \" + str(lr) + \", dropout_prob = \" + str(dropout_prob))\n",
    "        np.random.seed(1)\n",
    "        random.seed(1)\n",
    "        tf.random.set_seed(1)\n",
    "        if use_tpu: \n",
    "            with strategy.scope():\n",
    "                model = create_model(lr, dropout_prob)\n",
    "        else:\n",
    "            model = create_model(lr, dropout_prob) \n",
    "        history = model.fit(\n",
    "            x_train,\n",
    "            y2_train,\n",
    "            validation_data=(x_eval,y2_eval),\n",
    "            epochs=20, \n",
    "            verbose=1,\n",
    "            batch_size=128,\n",
    "            callbacks=[callback],\n",
    "        )\n",
    "        results = model.evaluate(x_eval, y2_eval, batch_size=128)\n",
    "        print(f\"Results validation: {results}, Learning rate =  {lr}, dropout_prob = {dropout_prob}\")\n",
    "        print('-'*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "# SQuAD2.0\n",
    "# file_name = \"SQuAD2.0_\"\n",
    "# lr = 5e-05\n",
    "# dropout_prob = 0.2\n",
    "\n",
    "# NewsQA\n",
    "# file_name = \"NewsQA_\"\n",
    "# lr = 9E-06\n",
    "# dropout_prob = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "if use_tpu: \n",
    "    with strategy.scope():\n",
    "        model = create_model(lr, dropout_prob)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y2_train,\n",
    "    validation_data=(x_eval,y2_eval),\n",
    "    epochs=20, \n",
    "    verbose=1,\n",
    "    batch_size=128,\n",
    "    callbacks=[callback],\n",
    ")\n",
    "model.evaluate(x_test, y2_test, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['exact_match']\n",
    "val_acc = history.history['val_exact_match']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "f1 = history.history['f1_m']\n",
    "val_f1 = history.history['val_f1_m']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.fill_between(epochs, loss,val_loss,color='g',alpha=.1)\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs, acc, label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "plt.fill_between(epochs, acc,val_acc,color='g',alpha=.1)\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs, f1, label='Training F1-Score')\n",
    "plt.plot(epochs, val_f1, label='Validation F1-Score')\n",
    "plt.fill_between(epochs, f1,val_f1,color='g',alpha=.1)\n",
    "plt.title('Training and validation F1-Score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(x_test, verbose=1)\n",
    "eval_pred = model.predict(x_eval, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip and copy the results\n",
    "\n",
    "algorithm = \"milp_\"\n",
    "file_list = []\n",
    "\n",
    "def save_to_file(name, data):\n",
    "    json_string = json.dumps(data.tolist())\n",
    "    file = algorithm + file_name + name\n",
    "    file_list.append(file)\n",
    "    with open(file, \"w\") as text_file:\n",
    "        text_file.write(json_string)\n",
    "\n",
    "save_to_file(\"test_pred.txt\", test_pred)\n",
    "save_to_file(\"eval_pred.txt\", eval_pred)\n",
    "\n",
    "save_to_file(\"y2_eval.txt\", y2_eval)\n",
    "save_to_file(\"y3_eval.txt\", np.array([v.tolist() for v in y3_eval]))\n",
    "\n",
    "save_to_file(\"y2_test.txt\", y2_test)\n",
    "save_to_file(\"y3_test.txt\", np.array([v.tolist() for v in y3_test]))\n",
    "\n",
    "save_to_file(\"token_type_eval.txt\", x_eval[1])\n",
    "save_to_file(\"token_type_test.txt\", x_test[1])\n",
    "\n",
    "save_to_file(\"input_ids_test.txt\", x_test[0])\n",
    "\n",
    "\n",
    "tar = tarfile.open(algorithm + file_name + \"predictions.tar.gz\", \"w:gz\")\n",
    "for name in file_list:\n",
    "    tar.add(name)\n",
    "tar.close()\n",
    "\n",
    "!mv *predictions.tar.gz /content/drive/MyDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "model = create_model(5e-05, 0) \n",
    "i = 16\n",
    "history = model.fit(\n",
    "        [x_test[0][0:i],x_test[1][0:i],x_test[2][0:i]],\n",
    "        y2_test[0:i],\n",
    "        epochs=2, \n",
    "        verbose=1,\n",
    "        batch_size=4,\n",
    "    )\n",
    "model.evaluate([x_test[0][0:i],x_test[1][0:i],x_test[2][0:i]],y2_test[0:i], batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
